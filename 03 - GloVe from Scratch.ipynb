{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GloVE\n",
        "\n",
        "Let's work on implementation of GloVE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Define some very simple data for understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\",\n",
        "                 \"dog cat animal\", \"cat animal dog\", \"cat dog animal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'animal', 'dog'],\n",
              " ['cat', 'dog', 'animal']]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = [sent.split(\" \") for sent in corpus]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fruit', 'banana', 'apple', 'dog', 'cat', 'animal']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'fruit': 0, 'banana': 1, 'apple': 2, 'dog': 3, 'cat': 4, 'animal': 5}\n"
          ]
        }
      ],
      "source": [
        "#numericalization\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "print(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "#vocab size\n",
        "voc_size = len(vocab)\n",
        "print(voc_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#append UNK\n",
        "vocab.append('<UNK>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fruit', 'banana', 'apple', 'dog', 'cat', 'animal', '<UNK>']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2index['<UNK>'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#just in case we need to use\n",
        "index2word = {v:k for k, v in word2index.items()} "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build Co-occurence Matrix X"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we need to count the co-occurence of two words given some window size.  We gonna use window size of 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'apple': 3, 'banana': 3, 'fruit': 3, 'dog': 3, 'cat': 3, 'animal': 3})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "X_i = Counter(flatten(corpus)) # X_i\n",
        "X_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('banana', 'apple'),\n",
              " ('banana', 'fruit'),\n",
              " ('apple', 'banana'),\n",
              " ('apple', 'fruit'),\n",
              " ('fruit', 'banana'),\n",
              " ('fruit', 'apple'),\n",
              " ('cat', 'dog'),\n",
              " ('cat', 'animal'),\n",
              " ('animal', 'cat'),\n",
              " ('animal', 'dog'),\n",
              " ('dog', 'cat'),\n",
              " ('dog', 'animal')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make skip gram of one size window\n",
        "skip_grams = []\n",
        "# loop each word sequence\n",
        "# we starts from 1 because 0 has no context\n",
        "# we stop at second last for the same reason\n",
        "for sent in corpus:\n",
        "    for i in range(1, len(sent) - 1):\n",
        "        target = sent[i]\n",
        "        context = [sent[i - 1], sent[i + 1]]\n",
        "        for w in context:\n",
        "            skip_grams.append((target, w))\n",
        "\n",
        "skip_grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({('banana', 'apple'): 1,\n",
              "         ('banana', 'fruit'): 1,\n",
              "         ('apple', 'banana'): 1,\n",
              "         ('apple', 'fruit'): 1,\n",
              "         ('fruit', 'banana'): 1,\n",
              "         ('fruit', 'apple'): 1,\n",
              "         ('cat', 'dog'): 1,\n",
              "         ('cat', 'animal'): 1,\n",
              "         ('animal', 'cat'): 1,\n",
              "         ('animal', 'dog'): 1,\n",
              "         ('dog', 'cat'): 1,\n",
              "         ('dog', 'animal'): 1})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_ik_skipgram = Counter(skip_grams) # Co-occurece in window size 1\n",
        "X_ik_skipgram"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Weighting function\n",
        "\n",
        "GloVe includes a weighting function to scale down too frequent words.\n",
        "\n",
        "<img src = \"figures/glove_weighting_func.png\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#simply a normalized function...don't worry too much\n",
        "def weighting(w_i, w_j, X_ik):\n",
        "        \n",
        "    #check whether the co-occurrences exist between these two words\n",
        "    try:\n",
        "        x_ij = X_ik[(w_i, w_j)]\n",
        "    except:\n",
        "        x_ij = 1  #if does not exist, set it to 1\n",
        "                \n",
        "    x_max = 100 #100 # fixed in paper  #cannot exceed 100 counts\n",
        "    alpha = 0.75\n",
        "    \n",
        "    #if co-occurrence does not exceed 100, scale it based on some alpha\n",
        "    if x_ij < x_max:\n",
        "        result = (x_ij/x_max)**alpha  #scale it\n",
        "    else:\n",
        "        result = 1  #if is greater than max, set it to 1 maximum\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_ik={('fruit', 'banana'): 2, ('banana', 'fruit'): 2, ('fruit', 'apple'): 2, ('apple', 'fruit'): 2, ('banana', 'apple'): 2, ('apple', 'banana'): 2, ('dog', 'cat'): 2, ('cat', 'dog'): 2, ('dog', 'animal'): 2, ('animal', 'dog'): 2, ('cat', 'animal'): 2, ('animal', 'cat'): 2}\n",
            "weighting_dic={('fruit', 'fruit'): 0.03162277660168379, ('fruit', 'banana'): 0.053182958969449884, ('banana', 'fruit'): 0.053182958969449884, ('fruit', 'apple'): 0.053182958969449884, ('apple', 'fruit'): 0.053182958969449884, ('fruit', 'dog'): 0.03162277660168379, ('dog', 'fruit'): 0.03162277660168379, ('fruit', 'cat'): 0.03162277660168379, ('cat', 'fruit'): 0.03162277660168379, ('fruit', 'animal'): 0.03162277660168379, ('animal', 'fruit'): 0.03162277660168379, ('fruit', '<UNK>'): 0.03162277660168379, ('<UNK>', 'fruit'): 0.03162277660168379, ('banana', 'banana'): 0.03162277660168379, ('banana', 'apple'): 0.053182958969449884, ('apple', 'banana'): 0.053182958969449884, ('banana', 'dog'): 0.03162277660168379, ('dog', 'banana'): 0.03162277660168379, ('banana', 'cat'): 0.03162277660168379, ('cat', 'banana'): 0.03162277660168379, ('banana', 'animal'): 0.03162277660168379, ('animal', 'banana'): 0.03162277660168379, ('banana', '<UNK>'): 0.03162277660168379, ('<UNK>', 'banana'): 0.03162277660168379, ('apple', 'apple'): 0.03162277660168379, ('apple', 'dog'): 0.03162277660168379, ('dog', 'apple'): 0.03162277660168379, ('apple', 'cat'): 0.03162277660168379, ('cat', 'apple'): 0.03162277660168379, ('apple', 'animal'): 0.03162277660168379, ('animal', 'apple'): 0.03162277660168379, ('apple', '<UNK>'): 0.03162277660168379, ('<UNK>', 'apple'): 0.03162277660168379, ('dog', 'dog'): 0.03162277660168379, ('dog', 'cat'): 0.053182958969449884, ('cat', 'dog'): 0.053182958969449884, ('dog', 'animal'): 0.053182958969449884, ('animal', 'dog'): 0.053182958969449884, ('dog', '<UNK>'): 0.03162277660168379, ('<UNK>', 'dog'): 0.03162277660168379, ('cat', 'cat'): 0.03162277660168379, ('cat', 'animal'): 0.053182958969449884, ('animal', 'cat'): 0.053182958969449884, ('cat', '<UNK>'): 0.03162277660168379, ('<UNK>', 'cat'): 0.03162277660168379, ('animal', 'animal'): 0.03162277660168379, ('animal', '<UNK>'): 0.03162277660168379, ('<UNK>', 'animal'): 0.03162277660168379, ('<UNK>', '<UNK>'): 0.03162277660168379}\n"
          ]
        }
      ],
      "source": [
        "from itertools import combinations_with_replacement\n",
        "\n",
        "X_ik = {}  #for keeping the co-occurences\n",
        "weighting_dic = {} #scaling the percentage of sampling\n",
        "\n",
        "for bigram in combinations_with_replacement(vocab, 2):\n",
        "    if X_ik_skipgram.get(bigram) is not None:  #matches \n",
        "        co_occer = X_ik_skipgram[bigram]  #get the count from what we already counted\n",
        "        X_ik[bigram] = co_occer + 1 # + 1 for stability issue\n",
        "        X_ik[(bigram[1],bigram[0])] = co_occer+1   #count also for the opposite\n",
        "    else:\n",
        "        pass\n",
        "        \n",
        "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
        "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)\n",
        "\n",
        "print(f\"{X_ik=}\")\n",
        "print(f\"{weighting_dic=}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Prepare train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'fruit']\n",
            "['banana', 'apple', 'fruit']\n",
            "['banana', 'fruit', 'apple']\n",
            "['dog', 'cat', 'animal']\n",
            "['cat', 'animal', 'dog']\n",
            "['cat', 'dog', 'animal']\n"
          ]
        }
      ],
      "source": [
        "for c in corpus:\n",
        "    print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
        "    \n",
        "    #convert to id since our skip_grams is word, not yet id\n",
        "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_coocs  = []\n",
        "    random_weightings = []\n",
        "    random_index = np.random.choice(range(len(skip_grams_id)), batch_size, replace=False) #randomly pick without replacement\n",
        "        \n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams_id[i][0]])  # target, e.g., 2\n",
        "        random_labels.append([skip_grams_id[i][1]])  # context word, e.g., 3\n",
        "        \n",
        "        #get cooc\n",
        "        pair = skip_grams[i]\n",
        "        try:\n",
        "            cooc = X_ik[pair]\n",
        "        except:\n",
        "            cooc = 1\n",
        "        random_coocs.append([math.log(cooc)])\n",
        "        \n",
        "        #get weighting\n",
        "        weighting = weighting_dic[pair]\n",
        "        random_weightings.append([weighting])\n",
        "                    \n",
        "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weightings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  [[4]\n",
            " [0]]\n",
            "Target:  [[5]\n",
            " [2]]\n",
            "Cooc:  [[0.69314718]\n",
            " [0.69314718]]\n",
            "Weighting:  [[0.05318296]\n",
            " [0.05318296]]\n"
          ]
        }
      ],
      "source": [
        "#testing the method\n",
        "batch_size = 2 # mini-batch size\n",
        "input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "\n",
        "print(\"Input: \", input_batch)\n",
        "print(\"Target: \", target_batch)\n",
        "print(\"Cooc: \", cooc_batch)\n",
        "print(\"Weighting: \", weighting_batch)\n",
        "\n",
        "#we will convert them to tensor during training, so don't worry..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model\n",
        "\n",
        "<img src =\"figures/glove.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GloVe(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size,embed_size):\n",
        "        super(GloVe,self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, embed_size) # center embedding\n",
        "        self.embedding_u = nn.Embedding(vocab_size, embed_size) # out embedding\n",
        "        \n",
        "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
        "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
        "        \n",
        "    def forward(self, center_words, target_words, coocs, weighting):\n",
        "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
        "        \n",
        "        center_bias = self.v_bias(center_words).squeeze(1)\n",
        "        target_bias = self.u_bias(target_words).squeeze(1)\n",
        "        \n",
        "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "        \n",
        "        #note that coocs already got log\n",
        "        loss = weighting*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
        "        \n",
        "        return torch.sum(loss)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size     = 10 # mini-batch size\n",
        "embedding_size = 2 #so we can later plot\n",
        "model          = GloVe(voc_size, embedding_size)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000 | cost: 0.005334 | time: 0m 0s\n",
            "Epoch: 2000 | cost: 0.000001 | time: 0m 0s\n",
            "Epoch: 3000 | cost: 0.000000 | time: 0m 0s\n",
            "Epoch: 4000 | cost: 0.000000 | time: 0m 0s\n",
            "Epoch: 5000 | cost: 0.000000 | time: 0m 0s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "    input_batch  = torch.LongTensor(input_batch)         #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch)        #[batch_size, 1]\n",
        "    cooc_batch   = torch.FloatTensor(cooc_batch)         #[batch_size, 1]\n",
        "    weighting_batch = torch.FloatTensor(weighting_batch) #[batch_size, 1]\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = model(input_batch, target_batch, cooc_batch, weighting_batch)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Plotting the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fruit', 'banana', 'apple', 'dog', 'cat', 'animal', '<UNK>']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#list of vocabs\n",
        "vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "word = vocab[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#numericalization\n",
        "id = word2index[word]\n",
        "id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_tensor = torch.LongTensor([id])\n",
        "id_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-1.0208, -0.5569]], grad_fn=<EmbeddingBackward0>),\n",
              " tensor([[ 0.6037, -0.1164]], grad_fn=<EmbeddingBackward0>))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get the embedding by averaging\n",
        "v_embed = model.embedding_v(id_tensor)\n",
        "u_embed = model.embedding_u(id_tensor)\n",
        "\n",
        "v_embed, u_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-0.3366, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#average to get the word embedding\n",
        "word_embed = (v_embed + u_embed) / 2\n",
        "word_embed[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's write a function to get embedding given a word\n",
        "def get_embed(word):\n",
        "    id_tensor = torch.LongTensor([word2index[word]])\n",
        "    v_embed = model.embedding_v(id_tensor)\n",
        "    u_embed = model.embedding_u(id_tensor) \n",
        "    word_embed = (v_embed + u_embed) / 2 \n",
        "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocab[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Cosine similarity\n",
        "\n",
        "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
        "\n",
        "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
        "\n",
        "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fruit', 'banana', 'apple', 'dog', 'cat', 'animal', '<UNK>']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's try similarity between first and second, and second and third\n",
        "cat          = get_embed('cat')\n",
        "fruit        = get_embed('fruit')\n",
        "animal       = get_embed('animal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  -0.908140396808316\n",
            "cat vs. animal:  0.9815125614101038\n",
            "cat vs. cat:  1.0\n"
          ]
        }
      ],
      "source": [
        "#numpy version\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "    \n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  -0.9081403968083159\n",
            "cat vs. animal:  0.9815125614101038\n",
            "cat vs. cat:  1.0\n"
          ]
        }
      ],
      "source": [
        "#scipy version\n",
        "from scipy import spatial\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n",
        "    return cos_sim\n",
        "\n",
        "print(f\"cat vs. fruit: \",     cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
